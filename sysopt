#!/usr/bin/env bash
# Define color codes for better readability
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# Version information
VERSION="3.0"
LAST_UPDATED="2025-01-30"

# Global variables for system information
declare -A CPU_INFO
declare -A MEM_INFO
declare -A DISK_INFO
declare -A NET_INFO
declare -A GPU_INFO
declare -A NUMA_INFO

# Function to detect and classify hardware capabilities
detect_hardware() {
    echo -e "${BLUE}Performing comprehensive hardware detection...${NC}"
    
    # CPU Detection and Classification
    CPU_INFO[vendor]=$(grep -m1 'vendor_id' /proc/cpuinfo | awk '{print $3}')
    CPU_INFO[model]=$(lscpu | grep "Model name" | cut -d ":" -f2 | sed 's/^[ \t]*//')
    CPU_INFO[cores]=$(lscpu | grep "^CPU(s):" | cut -d ":" -f2 | sed 's/^[ \t]*//')
    CPU_INFO[threads_per_core]=$(lscpu | grep "Thread(s) per core" | cut -d ":" -f2 | sed 's/^[ \t]*//')
    CPU_INFO[cache_size]=$(lscpu | grep "L3 cache" | cut -d ":" -f2 | sed 's/^[ \t]*//')
    CPU_INFO[architecture]=$(uname -m)
    
    # Detect hybrid architecture (e.g., Intel big.LITTLE)
    if grep -q "hybrid" /proc/cpuinfo; then
        CPU_INFO[hybrid]=true
        # Detect P-cores and E-cores
        CPU_INFO[p_cores]=$(grep -c "efficiency=0" /sys/devices/system/cpu/cpu*/topology/efficiency 2>/dev/null || echo "0")
        CPU_INFO[e_cores]=$(grep -c "efficiency=1" /sys/devices/system/cpu/cpu*/topology/efficiency 2>/dev/null || echo "0")
    else
        CPU_INFO[hybrid]=false
    fi

    # Memory Detection
    MEM_INFO[total]=$(free -b | grep "Mem:" | awk '{print $2}')
    MEM_INFO[available]=$(free -b | grep "Mem:" | awk '{print $7}')
    MEM_INFO[swap_total]=$(free -b | grep "Swap:" | awk '{print $2}')
    MEM_INFO[numa_nodes]=$(lscpu | grep "NUMA node(s):" | awk '{print $3}')
    MEM_INFO[memory_type]=$(dmidecode -t memory 2>/dev/null | grep -m1 "Type:" | awk '{print $2}')
    MEM_INFO[memory_speed]=$(dmidecode -t memory 2>/dev/null | grep -m1 "Speed:" | awk '{print $2}')

    # Storage Detection
    for device in $(lsblk -d -n -o NAME); do
        # Detect device type (nvme, ssd, hdd)
        if [[ $device == nvme* ]]; then
            DISK_INFO[${device}_type]="nvme"
            DISK_INFO[${device}_queue_depth]=$(cat /sys/block/${device}/device/queue_depth 2>/dev/null || echo "0")
        else
            if [[ $(cat /sys/block/${device}/queue/rotational 2>/dev/null) == "0" ]]; then
                DISK_INFO[${device}_type]="ssd"
            else
                DISK_INFO[${device}_type]="hdd"
            fi
        fi
        DISK_INFO[${device}_scheduler]=$(cat /sys/block/${device}/queue/scheduler 2>/dev/null | grep -o "\[.*\]" | tr -d "[]")
    done

    # Network Interface Detection
    for iface in $(ip -o link show | awk -F': ' '{print $2}' | grep -v "lo"); do
        if [[ -d "/sys/class/net/${iface}" ]]; then
            NET_INFO[${iface}_driver]=$(ethtool -i ${iface} 2>/dev/null | grep "driver:" | cut -d: -f2 | tr -d ' ')
            NET_INFO[${iface}_speed]=$(ethtool ${iface} 2>/dev/null | grep "Speed:" | cut -d: -f2 | tr -d ' ')
            NET_INFO[${iface}_features]=$(ethtool -k ${iface} 2>/dev/null | grep "tcp-segmentation-offload:" | awk '{print $2}')
        fi
    done

    # GPU Detection
    if command -v nvidia-smi &> /dev/null; then
        GPU_INFO[vendor]="nvidia"
        GPU_INFO[model]=$(nvidia-smi --query-gpu=gpu_name --format=csv,noheader 2>/dev/null)
        GPU_INFO[memory]=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader 2>/dev/null)
    elif command -v rocm-smi &> /dev/null; then
        GPU_INFO[vendor]="amd"
        GPU_INFO[model]=$(rocm-smi --showproductname 2>/dev/null | grep "GPU" | cut -d: -f2)
        GPU_INFO[memory]=$(rocm-smi --showmeminfo vram 2>/dev/null | grep "Total" | awk '{print $2}')
    fi

    # NUMA Topology Detection
    if [[ ${MEM_INFO[numa_nodes]} -gt 1 ]]; then
        for node in $(seq 0 $((${MEM_INFO[numa_nodes]}-1))); do
            NUMA_INFO[node${node}_cpus]=$(numactl -H | grep "node ${node} cpus:" | cut -d: -f2)
            NUMA_INFO[node${node}_memory]=$(numactl -H | grep "node ${node} size:" | awk '{print $4}')
        done
    fi
}

# Function to generate CPU-specific optimizations
optimize_cpu() {
    local output_file="/etc/sysctl.d/99-cpu-performance.conf"
    echo "# CPU Optimizations generated by Advanced System Optimizer v${VERSION}" > "$output_file"

    # Base CPU optimizations
    echo "kernel.sched_migration_cost_ns = 5000000" >> "$output_file"
    echo "kernel.sched_autogroup_enabled = 0" >> "$output_file"
    echo "kernel.sched_min_granularity_ns = 10000000" >> "$output_file"
    echo "kernel.sched_wakeup_granularity_ns = 15000000" >> "$output_file"

    # Vendor-specific optimizations
    case ${CPU_INFO[vendor]} in
        "GenuineIntel")
            if [[ ${CPU_INFO[hybrid]} == "true" ]]; then
                # Hybrid architecture optimizations (e.g., Alder Lake, Raptor Lake)
                echo "# Hybrid CPU Optimizations" >> "$output_file"
                echo "kernel.sched_hybrid_prefer_perf = 1" >> "$output_file"
                
                # Create CPU sets for P-cores and E-cores
                mkdir -p /etc/cgroup2/cpu
                echo "+cpu" > /etc/cgroup2/cpu/cgroup.subtree_control
                mkdir -p /etc/cgroup2/cpu/p_cores
                mkdir -p /etc/cgroup2/cpu/e_cores
                
                # Assign cores to appropriate groups
                echo "${CPU_INFO[p_cores]}" > /etc/cgroup2/cpu/p_cores/cpuset.cpus
                echo "${CPU_INFO[e_cores]}" > /etc/cgroup2/cpu/e_cores/cpuset.cpus
            else
                # Standard Intel optimizations
                echo "# Intel CPU Optimizations" >> "$output_file"
                echo "kernel.intel_idle.max_cstate = 1" >> "$output_file"
            fi
            ;;
        "AuthenticAMD")
            # AMD-specific optimizations
            echo "# AMD CPU Optimizations" >> "$output_file"
            echo "kernel.sched_core_rotate = 1" >> "$output_file"
            
            # Enable Precision Boost Overdrive if available
            if [[ -f /sys/devices/system/cpu/cpu0/cpufreq/amd_pstate_preferred_cpb ]]; then
                echo "1" > /sys/devices/system/cpu/cpu0/cpufreq/amd_pstate_preferred_cpb
            fi
            ;;
    esac

    # NUMA optimizations if applicable
    if [[ ${MEM_INFO[numa_nodes]} -gt 1 ]]; then
        echo "# NUMA Optimizations" >> "$output_file"
        echo "kernel.numa_balancing = 1" >> "$output_file"
        echo "vm.zone_reclaim_mode = 1" >> "$output_file"
        
        # Create NUMA-aware CPU sets
        for node in $(seq 0 $((${MEM_INFO[numa_nodes]}-1))); do
            mkdir -p /etc/cgroup2/cpu/numa_node${node}
            echo "${NUMA_INFO[node${node}_cpus]}" > /etc/cgroup2/cpu/numa_node${node}/cpuset.cpus
            echo "${node}" > /etc/cgroup2/cpu/numa_node${node}/cpuset.mems
        done
    fi
}

# Function to optimize memory settings
optimize_memory() {
    local output_file="/etc/sysctl.d/99-memory-performance.conf"
    echo "# Memory Optimizations generated by Advanced System Optimizer v${VERSION}" > "$output_file"

    local total_ram_gb=$((${MEM_INFO[total]} / 1024 / 1024 / 1024))
    local page_size=$(getconf PAGE_SIZE)
    
    # Calculate optimal values based on total RAM
    local vm_min_free_kb=$((total_ram_gb * 1024 * 3 / 100)) # 3% of total RAM
    local vm_dirty_ratio=$((total_ram_gb > 64 ? 10 : 20))
    local vm_dirty_background_ratio=$((vm_dirty_ratio / 2))
    
    # Base memory optimizations
    cat >> "$output_file" << EOF
# Memory Management
vm.min_free_kbytes = ${vm_min_free_kb}
vm.swappiness = 10
vm.vfs_cache_pressure = 50
vm.dirty_ratio = ${vm_dirty_ratio}
vm.dirty_background_ratio = ${vm_dirty_background_ratio}
vm.dirty_expire_centisecs = 3000
vm.dirty_writeback_centisecs = 500

# File System and I/O
fs.file-max = 2097152
fs.inotify.max_user_watches = 524288
fs.aio-max-nr = 1048576

# Transparent Hugepages
EOF

    # Configure Transparent Hugepages based on workload
    if [[ ${MEM_INFO[total]} -gt $((64*1024*1024*1024)) ]]; then # More than 64GB RAM
        echo "vm.transparent_hugepage.enabled = always" >> "$output_file"
        echo "vm.transparent_hugepage.defrag = always" >> "$output_file"
        # Calculate optimal huge pages (5% of RAM)
        local huge_pages=$((total_ram_gb * 1024 * 5 / 100 / 2048))
        echo "vm.nr_hugepages = ${huge_pages}" >> "$output_file"
    else
        echo "vm.transparent_hugepage.enabled = madvise" >> "$output_file"
        echo "vm.transparent_hugepage.defrag = madvise" >> "$output_file"
    fi

    # Memory compaction and reclaim settings
    cat >> "$output_file" << EOF
# Memory Compaction
vm.compact_unevictable_allowed = 1
vm.compaction_proactiveness = 100
vm.page-cluster = 3

# Direct Memory Access
vm.dma_reserved_size = $((page_size * 2048))
EOF
}

# Function to optimize storage devices
optimize_storage() {
    local output_file="/etc/udev/rules.d/60-storage-optimizations.rules"
    echo "# Storage Optimizations generated by Advanced System Optimizer v${VERSION}" > "$output_file"

    # Create optimized I/O scheduler rules based on device type
    for device in ${!DISK_INFO[@]}; do
        if [[ $device == *"_type" ]]; then
            local dev_name=${device%_type}
            local dev_type=${DISK_INFO[$device]}
            
            case $dev_type in
                "nvme")
                    # NVMe optimizations
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/scheduler}=\"none\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/read_ahead_kb}=\"2048\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/nr_requests}=\"2048\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/rq_affinity}=\"2\"" >> "$output_file"
                    ;;
                "ssd")
                    # SSD optimizations
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/scheduler}=\"bfq\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/read_ahead_kb}=\"512\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/nr_requests}=\"1024\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==="${dev_name}\", ATTR{queue/rq_affinity}=\"2\"" >> "$output_file"
                    ;;
                "hdd")
                    # HDD optimizations
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/scheduler}=\"bfq\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/read_ahead_kb}=\"4096\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/nr_requests}=\"4096\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/rq_affinity}=\"2\"" >> "$output_file"
                    echo "ACTION==\"add|change\", KERNEL==\"${dev_name}\", ATTR{queue/wbt_lat_usec}=\"75000\"" >> "$output_file"
                    ;;
            esac
        fi
    done

    # Configure the I/O scheduler system-wide
    local sysctl_io="/etc/sysctl.d/99-io-performance.conf"
    cat > "$sysctl_io" << EOF
# I/O Performance Optimizations
vm.dirty_bytes = 536870912
vm.dirty_background_bytes = 268435456
vm.dirty_expire_centisecs = 3000
vm.dirty_writeback_centisecs = 500
vm.page-cluster = 0
EOF
}

# Function to optimize network settings
optimize_network() {
    local output_file="/etc/sysctl.d/99-network-performance.conf"
    echo "# Network Optimizations generated by Advanced System Optimizer v${VERSION}" > "$output_file"

    # Detect maximum network speed across all interfaces
    local max_speed=0
    for iface in ${!NET_INFO[@]}; do
        if [[ $iface == *"_speed" ]]; then
            local speed=${NET_INFO[$iface]//[!0-9]/}
            if [[ $speed -gt $max_speed ]]; then
                max_speed=$speed
            fi
        fi
    done

    # Calculate optimal buffer sizes based on network speed
    local rmem_max=$((max_speed * 1024 * 1024 / 8)) # Convert to bytes
    local wmem_max=$rmem_max
    
    cat >> "$output_file" << EOF
# TCP Memory Allocation
net.core.rmem_max = $rmem_max
net.core.wmem_max = $wmem_max
net.core.rmem_default = $((rmem_max / 4))
net.core.wmem_default = $((wmem_max / 4))
net.ipv4.tcp_rmem = 4096 87380 $rmem_max
net.ipv4.tcp_wmem = 4096 65536 $wmem_max
net.ipv4.udp_rmem_min = 8192
net.ipv4.udp_wmem_min = 8192

# TCP Performance
net.ipv4.tcp_fastopen = 3
net.ipv4.tcp_slow_start_after_idle = 0
net.ipv4.tcp_no_metrics_save = 1
net.ipv4.tcp_mtu_probing = 1
net.core.netdev_max_backlog = 16384
net.core.somaxconn = 8192
net.ipv4.tcp_max_syn_backlog = 8192

# TCP Congestion Control
EOF

    # Select optimal congestion control algorithm
    if grep -q "bbr" /proc/sys/net/ipv4/tcp_available_congestion_control; then
        echo "net.ipv4.tcp_congestion_control = bbr" >> "$output_file"
        echo "net.core.default_qdisc = fq" >> "$output_file"
    else
        echo "net.ipv4.tcp_congestion_control = cubic" >> "$output_file"
        echo "net.core.default_qdisc = fq_codel" >> "$output_file"
    fi
}

# Function to optimize GPU settings if available
optimize_gpu() {
    if [[ -n "${GPU_INFO[vendor]}" ]]; then
        case ${GPU_INFO[vendor]} in
            "nvidia")
                # Create optimal Nvidia settings
                mkdir -p /etc/X11/xorg.conf.d/
                cat > /etc/X11/xorg.conf.d/30-nvidia.conf << EOF
Section "Device"
    Identifier "Nvidia Card"
    Driver "nvidia"
    Option "NoLogo" "true"
    Option "UseEvents" "true"
    Option "RegistryDwords" "PowerMizerEnable=0x1; PerfLevelSrc=0x2222"
    Option "TripleBuffer" "true"
EndSection
EOF
                # Set maximum performance mode
                nvidia-smi -pm 1
                nvidia-smi --auto-boost-default=0
                nvidia-smi -ac $(nvidia-smi -q -d SUPPORTED_CLOCKS | grep -A 1 "Memory" | tail -n 1 | awk '{print $1}'),$(nvidia-smi -q -d SUPPORTED_CLOCKS | grep -A 1 "Graphics" | tail -n 1 | awk '{print $1}')
                ;;
            "amd")
                # Create optimal AMD settings
                mkdir -p /etc/X11/xorg.conf.d/
                cat > /etc/X11/xorg.conf.d/20-amdgpu.conf << EOF
Section "Device"
    Identifier "AMD GPU"
    Driver "amdgpu"
    Option "TearFree" "true"
    Option "DRI" "3"
    Option "AccelMethod" "glamor"
EndSection
EOF
                # Set performance mode if available
                if [[ -f /sys/class/drm/card0/device/power_dpm_force_performance_level ]]; then
                    echo "high" > /sys/class/drm/card0/device/power_dpm_force_performance_level
                fi
                ;;
        esac
    fi
}

# Function to create a comprehensive backup
create_backup() {
    local backup_dir="/root/system_backup_$(date +%Y%m%d_%H%M%S)"
    echo -e "${BLUE}Creating comprehensive backup at ${backup_dir}...${NC}"
    
    mkdir -p "$backup_dir"/{sysctl,udev,xorg,grub}
    
    # Backup system configuration files
    cp -r /etc/sysctl.d/* "$backup_dir/sysctl/"
    cp -r /etc/udev/rules.d/* "$backup_dir/udev/" 2>/dev/null || true
    cp -r /etc/X11/xorg.conf.d/* "$backup_dir/xorg/" 2>/dev/null || true
    cp /etc/default/grub "$backup_dir/grub/"
    
    # Create restore script
    cat > "$backup_dir/restore.sh" << 'EOF'
#!/bin/bash
BACKUP_DIR=$(dirname "$0")

# Restore configurations
cp -r "$BACKUP_DIR/sysctl/"* /etc/sysctl.d/
cp -r "$BACKUP_DIR/udev/"* /etc/udev/rules.d/
cp -r "$BACKUP_DIR/xorg/"* /etc/X11/xorg.conf.d/
cp "$BACKUP_DIR/grub/grub" /etc/default/grub

# Apply changes
sysctl --system
update-grub
udevadm control --reload-rules
udevadm trigger

echo "System configuration restored from backup"
EOF
    chmod +x "$backup_dir/restore.sh"
    
    echo -e "${GREEN}Backup created. To restore, run: ${backup_dir}/restore.sh${NC}"
}

# Main function to orchestrate the optimization process
main() {
    # Check for root privileges
    if [[ $EUID -ne 0 ]]; then
        echo -e "${RED}This script must be run as root${NC}"
        exit 1
    fi

    # Parse command line arguments
    local mode="assess"
    local aggressive=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            assess|optimize)
                mode=$1
                shift
                ;;
            --aggressive)
                aggressive=true
                shift
                ;;
            --help|-h)
                echo "Usage: $0 [assess|optimize] [--aggressive] [--help]"
                echo "Options:"
                echo "  assess     - Only assess system and generate report"
                echo "  optimize   - Perform system optimization"
                echo "  --aggressive - Apply more aggressive optimizations"
                exit 0
                ;;
            *)
                echo -e "${RED}Unknown option: $1${NC}"
                exit 1
                ;;
        esac
    done

    # Detect hardware
    detect_hardware

    if [[ $mode == "assess" ]]; then
        # Generate detailed assessment report
        {
            echo "=== System Assessment Report ==="
            echo "Date: $(date)"
            echo "Version: $VERSION"
            
            echo -e "\n=== CPU Information ==="
            echo "Vendor: ${CPU_INFO[vendor]}"
            echo "Model: ${CPU_INFO[model]}"
            echo "Cores: ${CPU_INFO[cores]}"
            echo "Threads per Core: ${CPU_INFO[threads_per_core]}"
            echo "Architecture: ${CPU_INFO[architecture]}"
            [[ ${CPU_INFO[hybrid]} == "true" ]] && echo "Hybrid Architecture: P-cores=${CPU_INFO[p_cores]}, E-cores=${CPU_INFO[e_cores]}"
            
            echo -e "\n=== Memory Information ==="
            echo "Total RAM: $((${MEM_INFO[total]} / 1024 / 1024 / 1024)) GB"
            echo "Memory Type: ${MEM_INFO[memory_type]}"
            echo "Memory Speed: ${MEM_INFO[memory_speed]}"
            echo "NUMA Nodes: ${MEM_INFO[numa_nodes]}"
            
            echo -e "\n=== Storage Devices ==="
            for device in ${!DISK_INFO[@]}; do
                if [[ $device == *"_type" ]]; then
                    local dev_name=${device%_type}
                    echo "Device: $dev_name"
                    echo "Type: ${DISK_INFO[${device}]}"
                    echo "Current Scheduler: ${DISK_INFO[${dev_name}_scheduler]}"
                    echo
                fi
            done
            
            echo -e "\n=== Network Interfaces ==="
            for iface in ${!NET_INFO[@]}; do
                if [[ $iface == *"_driver" ]]; then
                    local if_name=${iface%_driver}
                    echo "Interface: $if_name"
                    echo "Driver: ${NET_INFO[${iface}]}"
                    echo "Speed: ${NET_INFO[${if_name}_speed]}"
                    echo "TCP Offload: ${NET_INFO[${if_name}_features]}"
                    echo
                fi
            done
            
            [[ -n "${GPU_INFO[vendor]}" ]] && {
                echo -e "\n=== GPU Information ==="
                echo "Vendor: ${GPU_INFO[vendor]}"
                echo "Model: ${GPU_INFO[model]}"
                echo "Memory: ${GPU_INFO[memory]}"
            }
            
        } | tee system_assessment_$(date +%Y%m%d_%H%M%S).txt
        
    else
        # Perform optimization
        echo -e "${BLUE}Starting system optimization...${NC}"
        
        # Create backup first
        create_backup
        
        # Apply optimizations
        optimize_cpu
        optimize_memory
        optimize_storage
        optimize_network
        [[ -n "${GPU_INFO[vendor]}" ]] && optimize_gpu
        
        # Apply all changes
        echo -e "${BLUE}Applying optimizations...${NC}"
        sysctl --system
        udevadm control --reload-rules
        udevadm trigger
        
        echo -e "${GREEN}Optimization complete. A reboot is required to apply all changes.${NC}"
        echo -e "${YELLOW}Note: A backup of your original configuration has been created.${NC}"
    fi
}

main "$@"
